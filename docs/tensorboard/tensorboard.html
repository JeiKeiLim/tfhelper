<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.4" />
<title>tfhelper.tensorboard.tensorboard API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>tfhelper.tensorboard.tensorboard</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import io
from tensorboard import program
import datetime
import time
import os
import glob


class ConfuseCallback(tf.keras.callbacks.Callback):
    &#34;&#34;&#34;
    Generate Confusion Matrix and write an image to TensorBoard
    &#34;&#34;&#34;
    def __init__(self, x_test, y_test, file_writer, dataset=None, class_names=None, figure_size=(12, 10), batch_size=32):
        &#34;&#34;&#34;
        Args:
            x_test (np.ndarray): (n data, data dimension(Ex. 32x32x3 or 600x30 ..., etc). If None is given, dataset must be provided.
            y_test (np.ndarray): (n data, ). If None is given, dataset must be provided.
            file_writer (tf.summary.SummaryWriter): TensorBoard File Writer
            dataset (tf.keras.dataset.Dataset): If dataset is given, x_test and y_test is ignored. Default: None.
            class_names (list of str): Names of class. If None, default names are set to (Class01, Class02 ...). Default: None.
            figure_size (tuple): Figure size of confusion matrix. Default: (12, 10).
            batch_size (int): Batch size to predict x_test. If dataset is given, batch_size is ignored and batch size set in dataset is used.
        &#34;&#34;&#34;
        super(ConfuseCallback, self).__init__()
        self.dataset = dataset
        self.x_test = x_test
        self.y_test = y_test

        if self.y_test is None and self.dataset is not None:
            self.y_test = []
            for i, xy in self.dataset.enumerate():
                y = xy[1].numpy()
                self.y_test = np.concatenate([self.y_test, y])
            self.y_test = self.y_test.astype(np.int32)

        self.y_test = self.y_test if len(self.y_test.shape) == 1 else np.argmax(self.y_test, axis=1)

        self.file_writer = file_writer
        self.figure_size = figure_size
        self.label_names = class_names
        self.batch_size = batch_size

        if self.label_names is None and self.y_test is not None:
            self.label_names = [&#34;Class {:02d}&#34;.format(unique_label) for unique_label in np.unique(self.y_test)]

    def get_precision_recall_plot(self, con_mat):
        &#34;&#34;&#34;
        Generate Precision and Recall plot bar plot image
        Args:
            con_mat (np.ndarray): Confusion Matrix array

        Returns:
            tf.TensorArray: Precision and Recall Bar Plot Image
            np.ndarray: Precisions
            np.ndarray: Recalls
        &#34;&#34;&#34;
        precisions = np.array([0] * len(self.label_names)).astype(&#39;float32&#39;)
        recalls = np.array([0] * len(self.label_names)).astype(&#39;float32&#39;)

        for i in range(con_mat.shape[0]):
            tp = con_mat[i, i]
            fn = (con_mat[i, :].sum() - tp)

            fp = (con_mat[:, i].sum() - tp)
            tn = (con_mat.diagonal().sum() - tp)

            # tpr = tp / np.sum(self.test_labels[()] == i)
            # fnr = fn / np.sum(self.test_labels[()] == i)
            # fpr = fp / np.sum(self.test_labels[()] != i)
            # tnr = tn / np.sum(self.test_labels[()] != i)

            precisions[i] = max(0, tp / (tp + fp))
            recalls[i] = max(0, tp / (tp + fn))

        df = pd.DataFrame((self.label_names, precisions, recalls)).T
        df.columns = [&#34;Class&#34;, &#34;Precision&#34;, &#34;Recall&#34;]
        df = pd.melt(df, id_vars=&#34;Class&#34;, var_name=&#34;Type&#34;, value_name=&#34;Value&#34;)

        figure = plt.figure(figsize=self.figure_size)
        sns.barplot(y=&#39;Class&#39;, x=&#39;Value&#39;, hue=&#39;Type&#39;, data=df)
        plt.tight_layout()

        buf = io.BytesIO()
        plt.savefig(buf, format=&#39;png&#39;)
        plt.close(figure)

        image = tf.image.decode_png(buf.getvalue(), channels=4)
        image = tf.expand_dims(image, 0)

        return image, precisions, recalls

    def on_epoch_end(self, epoch, logs=None):
        if self.dataset is None and (self.x_test is None or self.y_test is None):
            return

        try:
            if self.dataset is None:
                test_pred = []
                for b in range(0, self.x_test.shape[0], self.batch_size):
                    x_feed = self.x_test[b:b+self.batch_size]
                    pred = self.model.predict(x_feed)
                    pred = np.argmax(pred, axis=1)
                    test_pred = np.concatenate([test_pred, pred])
            else:
                test_pred = self.model.predict(self.dataset)
                test_pred = np.argmax(test_pred, axis=1)

            accuracy = np.sum(test_pred == self.y_test) / self.y_test.shape[0]

            con_mat = tf.math.confusion_matrix(labels=self.y_test, predictions=test_pred).numpy()
            con_mat_norm = np.around(con_mat.astype(&#39;float&#39;) / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)

            con_mat_df = pd.DataFrame(con_mat_norm,
                                      index=self.label_names,
                                      columns=self.label_names)

            precision_recall_image, precisions, recalls = self.get_precision_recall_plot(con_mat)

            figure = plt.figure(figsize=self.figure_size)
            sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)
            plt.ylabel(&#39;True label&#39;)
            plt.xlabel(&#39;Predicted label&#39;)
            plt.title(&#34;Accuracy : {:.2f}%, Precision : {:.2f}%, Recall : {:.2f}%&#34;.format(accuracy*100, precisions.mean()*100, recalls.mean()*100))

            plt.tight_layout()

            buf = io.BytesIO()
            plt.savefig(buf, format=&#39;png&#39;)

            plt.close(figure)
            buf.seek(0)
            image = tf.image.decode_png(buf.getvalue(), channels=4)

            image = tf.expand_dims(image, 0)

            # Log the confusion matrix as an image summary.
            with self.file_writer.as_default():
                tf.summary.image(&#34;Confusion Matrix&#34;, image, step=epoch)
                tf.summary.image(&#34;Precision and Recall&#34;, precision_recall_image, step=epoch)
        except Exception as e:
            print(e)


class ModelSaverCallback(tf.keras.callbacks.Callback):
    &#34;&#34;&#34;
    Saves Model at each end of the epoch when the best accuracy/loss is presented.
    &#34;&#34;&#34;
    def __init__(self, best_metric=float(&#39;inf&#39;), save_root=&#34;./&#34;, save_metric=&#39;val_loss&#39;, enable=True, epoch=0):
        &#34;&#34;&#34;

        Args:
            best_metric (float): Set best score of previous training session if resuming.
            save_root (str): Model save path
            save_metric (str): One of &#39;val_loss&#39;, &#39;val_accuracy&#39;
            enable (bool): Set previous epoch number if resuming
            epoch (int): Epoch number
        &#34;&#34;&#34;
        super(ModelSaverCallback, self).__init__()
        self.best_metric = best_metric
        if self.best_metric == float(&#39;inf&#39;) and save_metric.find(&#34;accuracy&#34;) &gt; 0:
            self.best_metric = -self.best_metric

        self.epoch = epoch
        self.save_root = save_root
        self.enable = enable
        self.save_metric = save_metric

    def on_epoch_end(self, epoch, logs=None):
        try:
            epoch += self.epoch
            a = logs[self.save_metric]
            b = self.best_metric

            if self.save_metric.find(&#34;accuracy&#34;) &gt; 0:
                a, b = b, a

            if a &lt; b:
                p_file_list = glob.glob(&#34;{}/*.h5&#34;.format(self.save_root))
                p_file_list = sorted(p_file_list, key=lambda x: x[-10:])
                if self.save_metric.find(&#34;accuracy&#34;) &lt; 0:
                    p_file_list = p_file_list[::-1]

                for i, file_path in enumerate(p_file_list):
                    if i+1 == len(p_file_list):
                        break
                    try:
                        os.remove(file_path)
                    except:
                        print(&#34;Error while deleting file : {}&#34;.format(file_path))

                file_name = &#39;{}/my_model_weight_{:04d}_{}_{:03.2f}.h5&#39;.format(self.save_root, epoch, self.save_metric, logs[self.save_metric])
                print(&#34;\nBest score! saving the model to {} ...&#34;.format(file_name))
                self.best_metric = logs[self.save_metric]

                if self.enable:
                    self.model.save(file_name)
        except Exception as e:
            print(e)


class SparsityCallback(tf.keras.callbacks.Callback):
    &#34;&#34;&#34;
    Computes the sparsity on each layer of the given model and saves bar plot image to the TensorBoard.
    &#34;&#34;&#34;
    def __init__(self, file_writer, sparsity_threshold=0.05, figure_size=(12, 20)):
        &#34;&#34;&#34;

        Args:
            file_writer (tf.summary.SummaryWriter): TensorBoard File Writer
            sparsity_threshold (float): Sparsity Threshold of each layer.
                                        Ex) 0.05 -&gt; Find the number of weights where -0.05 &lt; values &lt; 0.05 in a layer.
                                        Percentage of the number if set to the sparsity of the layer.
            figure_size (tuple): Figure size to generate plot image
        &#34;&#34;&#34;
        super(SparsityCallback, self).__init__()

        self.file_writer = file_writer
        self.sparsity_threshold = sparsity_threshold
        self.figure_size = list(figure_size)

    def get_sparsity_plot(self, sparse_levels, sparse_layer_names):
        &#34;&#34;&#34;
        Generate sparsity plot image

        Args:
            sparse_levels (np.ndarray): Sparse levels for the layer
            sparse_layer_names (list of str, np.ndarray): Names of layer along with sparse_levels list

        Returns:

        &#34;&#34;&#34;
        width = 0.8

        n_data = sparse_levels.shape[0]
        self.figure_size[1] = 0.25 * n_data

        fig, ax = plt.subplots(figsize=self.figure_size)
        ax.barh(sparse_layer_names, sparse_levels, width)

        for i, v in enumerate(sparse_levels):
            ax.text(v + 0.005, i - .15, f&#34;{v * 100:.2f}%&#34;, color=&#39;k&#39;, fontweight=&#39;bold&#39;)

        ax.set_title(f&#34;Sparsity Threshold: {self.sparsity_threshold}, Mean Sparsity: {sparse_levels.mean()*100:.2f}%&#34;)
        ax.set_xlim(0.0, 1.0)

        buf = io.BytesIO()
        fig.savefig(buf, format=&#39;png&#39;)
        plt.close(fig)

        image = tf.image.decode_png(buf.getvalue(), channels=4)
        image = tf.expand_dims(image, 0)

        return image

    def on_epoch_end(self, epoch, logs=None):
        sparsities = self.compute_sparsity()
        layer_names = [layer.name for layer in self.model.layers]

        sparse_levels = []
        sparse_layer_names = []

        for i, (sparsity, layer_name) in enumerate(zip(sparsities, layer_names)):
            if np.isnan(sparsity):
                continue
            sparse_levels = np.concatenate([sparse_levels, [sparsity]])
            sparse_layer_names = np.concatenate([sparse_layer_names, [f&#34;{i:03d}: {layer_name}&#34;]])

        try:
            sparsity_image = self.get_sparsity_plot(sparse_levels, sparse_layer_names)

            with self.file_writer.as_default():
                tf.summary.image(&#34;Sparsity Levels of Each Layer&#34;, sparsity_image, step=epoch)
        except Exception as e:
            print(e)

    def compute_sparsity(self):
        sparsities = np.zeros(len(self.model.layers))

        for i in range(sparsities.shape[0]):
            if len(self.model.layers[i].weights) &lt; 1:
                sparsities[i] = np.nan
                continue

            sparse_index = np.argwhere(
                np.logical_and(self.model.layers[i].weights[0].numpy().flatten() &lt; self.sparsity_threshold,
                               self.model.layers[i].weights[0].numpy().flatten() &gt; -self.sparsity_threshold))

            sparsities[i] = sparse_index.shape[0] / np.prod(self.model.layers[i].weights[0].shape)

        return sparsities


def run_tensorboard(path, host=&#39;0.0.0.0&#39;, port=6006):
    &#34;&#34;&#34;
    Run TensorBoard in python script.
    Args:
        path (str): TensorBoard log dir
        host(str): Host address for TensorBoard.
                    127.0.0.1 -&gt; localhost.
                    0.0.0.0 -&gt; Allow remote connection.
        port (int): Port number for TensorBoard

    Returns:
        None
    &#34;&#34;&#34;
    tb = program.TensorBoard()
    tb.configure(argv=[None, &#39;--logdir&#39;, path, &#39;--host&#39;, host, &#39;--port&#39;, f&#34;{port:}&#34;])
    url = tb.launch()

    print(&#34;Running tensorboard on {}&#34;.format(url))

    return url


def wait_ctrl_c(pre_msg=&#34;Press Ctrl+c to quit Tensorboard&#34;, post_msg=&#34;\nExit.&#34;):
    &#34;&#34;&#34;
    Wait until ctrl+c is pressed. This function is to prevent quitting python process when the training is completed when TensorBoard is running.
    Args:
        pre_msg: Message prior to wait ctrl+c
        post_msg: Message post to ctrl+c pressed

    Returns:
        None
    &#34;&#34;&#34;
    print(pre_msg)
    try:
        while True:
            time.sleep(3600)
    except KeyboardInterrupt:
        print(post_msg)


def get_tf_callbacks(root,
                     tboard_callback=True, tboard_update_freq=&#39;epoch&#39;, tboard_histogram_freq=1, tboard_profile_batch=0,
                     confuse_callback=True, label_info=None, x_test=None, y_test=None, test_generator_=None, test_dataset=None, figure_size=(12, 10),
                     modelsaver_callback=False, best_loss=float(&#39;inf&#39;), save_root=None, best_epoch=0, save_metric=&#39;val_loss&#39;,
                     earlystop_callback=True, earlystop_monitor=&#39;val_loss&#39;, earlystop_patience=0, earlystop_restore_weights=True,
                     sparsity_callback=False, sparsity_threshold=0.05):
    &#34;&#34;&#34;
    Getting TensorFlow callbacks function for convenience purpose.
    Args:
        root (str): Root directory for TensorBoard
        tboard_callback (bool): Whether using TensorBoard or not. Default: True
        tboard_update_freq (str): TensorBoard update frequency. (&#39;epoch&#39;, &#39;batch&#39;). Default: &#39;epoch&#39;
        tboard_histogram_freq (int): TensorBoard histogram update frequency. Default: 1
        tboard_profile_batch (int): TensorBoard profile timing. If 0 is given, profiling is not used.
                                Ex) If 10 is given, profiling is executed at batch of 10. Default: 0
        confuse_callback (bool): Whether using confusion matrix for TensorBoard callback or not.
                          At least one of the following three ((x_test, y_test), test_generator_, test_dataset) must be set.
                          Otherwise, Confusion Matrix callback will be ignored.
                          Default: True.
        label_info (list of str): Names of class. If None, default names are set to (Class01, Class02 ...). Default: None.
        x_test (np.ndarray, None): (n data, data dimension(Ex. 32x32x3 or 600x30 ..., etc). If None is given, dataset must be provided.
        y_test (np.ndarray, None): (n data, ). If None is given, dataset must be provided.
        test_generator_ (tfhelper.dataset.HDF5Generator, None): Default: None. For HDF5Generator test set purpose.
        test_dataset (tf.dataset.Dataset, None): Default: None.
        figure_size (tuple): Figure Size of Confusion Matrix.
        modelsaver_callback (bool): Whether using ModelSaver callback or not. Saving the model file when the lowest validation loss is given per each epochs.
                                        Default: False.
        best_loss (float): Set best score of previous training session if resuming.
        save_root (str): Model save path
        best_epoch (int): Previous Best epoch number if resuming
        save_metric (str): One of &#39;val_loss&#39;, &#39;val_accuracy&#39;
        earlystop_callbac (bool): Early Stop callback
        earlystop_monitor (str): Earlys top_monitor metric &#39;val_loss&#39;, &#39;val_accuracy&#39;
        earlystop_patience (int): Early stop patience
        earlystop_restore_weights (bool): Restore weights on early stop.
        sparsity_callback (bool): Sparsity callback.
        sparsity_threshold (float): Sparsity Threshold of each layer.
                            Ex) 0.05 -&gt; Find the number of weights where -0.05 &lt; values &lt; 0.05 in a layer.
                            Percentage of the number if set to the sparsity of the layer.

    Returns:
        list of tf.keras.callbacks.Callback: Callback List
        str: Tensor Board Log Root Directory

    &#34;&#34;&#34;
    postfix = datetime.datetime.now().strftime(&#34;%Y%m%d-%H%M%S&#34;)
    log_root_ = &#34;{}{}/&#34;.format(root, postfix)

    callbacks_ = []

    if tboard_callback:
        callbacks_.append(tf.keras.callbacks.TensorBoard(log_dir=&#34;{}fit&#34;.format(log_root_),
                                                         histogram_freq=tboard_histogram_freq,
                                                         update_freq=tboard_update_freq,
                                                         profile_batch=tboard_profile_batch)
                         )

    if confuse_callback:
        file_writer = tf.summary.create_file_writer(&#34;{}/cm&#34;.format(log_root_, postfix))

        x_test = test_generator_.data[&#39;test_data&#39;] if test_generator_ is not None else x_test
        y_test = test_generator_.data[&#39;test_label&#39;] if test_generator_ is not None else y_test

        if x_test is not None and y_test is not None:
            callbacks_.append(ConfuseCallback(x_test, y_test, file_writer, class_names=label_info,
                                              figure_size=figure_size)
                              )
        elif test_dataset is not None:
            callbacks_.append(ConfuseCallback(None, None, file_writer, dataset=test_dataset, class_names=label_info,
                                              figure_size=figure_size)
                              )

    if modelsaver_callback:
        if not save_root:
            save_root = log_root_
        callbacks_.append(
            ModelSaverCallback(best_metric=best_loss, save_root=save_root, epoch=best_epoch, save_metric=save_metric)
        )

    if earlystop_callback:
        callbacks_.append(tf.keras.callbacks.EarlyStopping(monitor=earlystop_monitor, patience=earlystop_patience,
                                                           restore_best_weights=earlystop_restore_weights))

    if sparsity_callback:
        file_writer = tf.summary.create_file_writer(&#34;{}/sparsity&#34;.format(log_root_, postfix))

        callbacks_.append(
            SparsityCallback(file_writer, sparsity_threshold=sparsity_threshold)
        )

    return callbacks_, log_root_</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="tfhelper.tensorboard.tensorboard.get_tf_callbacks"><code class="name flex">
<span>def <span class="ident">get_tf_callbacks</span></span>(<span>root, tboard_callback=True, tboard_update_freq='epoch', tboard_histogram_freq=1, tboard_profile_batch=0, confuse_callback=True, label_info=None, x_test=None, y_test=None, test_generator_=None, test_dataset=None, figure_size=(12, 10), modelsaver_callback=False, best_loss=inf, save_root=None, best_epoch=0, save_metric='val_loss', earlystop_callback=True, earlystop_monitor='val_loss', earlystop_patience=0, earlystop_restore_weights=True, sparsity_callback=False, sparsity_threshold=0.05)</span>
</code></dt>
<dd>
<div class="desc"><p>Getting TensorFlow callbacks function for convenience purpose.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>root</code></strong> :&ensp;<code>str</code></dt>
<dd>Root directory for TensorBoard</dd>
<dt><strong><code>tboard_callback</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether using TensorBoard or not. Default: True</dd>
<dt><strong><code>tboard_update_freq</code></strong> :&ensp;<code>str</code></dt>
<dd>TensorBoard update frequency. ('epoch', 'batch'). Default: 'epoch'</dd>
<dt><strong><code>tboard_histogram_freq</code></strong> :&ensp;<code>int</code></dt>
<dd>TensorBoard histogram update frequency. Default: 1</dd>
<dt><strong><code>tboard_profile_batch</code></strong> :&ensp;<code>int</code></dt>
<dd>TensorBoard profile timing. If 0 is given, profiling is not used.
Ex) If 10 is given, profiling is executed at batch of 10. Default: 0</dd>
<dt><strong><code>confuse_callback</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether using confusion matrix for TensorBoard callback or not.
At least one of the following three ((x_test, y_test), test_generator_, test_dataset) must be set.
Otherwise, Confusion Matrix callback will be ignored.
Default: True.</dd>
<dt><strong><code>label_info</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>Names of class. If None, default names are set to (Class01, Class02 &hellip;). Default: None.</dd>
<dt><strong><code>x_test</code></strong> :&ensp;<code>np.ndarray, None</code></dt>
<dd>(n data, data dimension(Ex. 32x32x3 or 600x30 &hellip;, etc). If None is given, dataset must be provided.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>np.ndarray, None</code></dt>
<dd>(n data, ). If None is given, dataset must be provided.</dd>
<dt><strong><code>test_generator_</code></strong> :&ensp;<code>tfhelper.dataset.HDF5Generator, None</code></dt>
<dd>Default: None. For HDF5Generator test set purpose.</dd>
<dt><strong><code>test_dataset</code></strong> :&ensp;<code>tf.dataset.Dataset, None</code></dt>
<dd>Default: None.</dd>
<dt><strong><code>figure_size</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Figure Size of Confusion Matrix.</dd>
<dt><strong><code>modelsaver_callback</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether using ModelSaver callback or not. Saving the model file when the lowest validation loss is given per each epochs.
Default: False.</dd>
<dt><strong><code>best_loss</code></strong> :&ensp;<code>float</code></dt>
<dd>Set best score of previous training session if resuming.</dd>
<dt><strong><code>save_root</code></strong> :&ensp;<code>str</code></dt>
<dd>Model save path</dd>
<dt><strong><code>best_epoch</code></strong> :&ensp;<code>int</code></dt>
<dd>Previous Best epoch number if resuming</dd>
<dt><strong><code>save_metric</code></strong> :&ensp;<code>str</code></dt>
<dd>One of 'val_loss', 'val_accuracy'</dd>
<dt><strong><code>earlystop_callbac</code></strong> :&ensp;<code>bool</code></dt>
<dd>Early Stop callback</dd>
<dt><strong><code>earlystop_monitor</code></strong> :&ensp;<code>str</code></dt>
<dd>Earlys top_monitor metric 'val_loss', 'val_accuracy'</dd>
<dt><strong><code>earlystop_patience</code></strong> :&ensp;<code>int</code></dt>
<dd>Early stop patience</dd>
<dt><strong><code>earlystop_restore_weights</code></strong> :&ensp;<code>bool</code></dt>
<dd>Restore weights on early stop.</dd>
<dt><strong><code>sparsity_callback</code></strong> :&ensp;<code>bool</code></dt>
<dd>Sparsity callback.</dd>
<dt><strong><code>sparsity_threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>Sparsity Threshold of each layer.
Ex) 0.05 -&gt; Find the number of weights where -0.05 &lt; values &lt; 0.05 in a layer.
Percentage of the number if set to the sparsity of the layer.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code> of <code>tf.keras.callbacks.Callback</code></dt>
<dd>Callback List</dd>
<dt><code>str</code></dt>
<dd>Tensor Board Log Root Directory</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_tf_callbacks(root,
                     tboard_callback=True, tboard_update_freq=&#39;epoch&#39;, tboard_histogram_freq=1, tboard_profile_batch=0,
                     confuse_callback=True, label_info=None, x_test=None, y_test=None, test_generator_=None, test_dataset=None, figure_size=(12, 10),
                     modelsaver_callback=False, best_loss=float(&#39;inf&#39;), save_root=None, best_epoch=0, save_metric=&#39;val_loss&#39;,
                     earlystop_callback=True, earlystop_monitor=&#39;val_loss&#39;, earlystop_patience=0, earlystop_restore_weights=True,
                     sparsity_callback=False, sparsity_threshold=0.05):
    &#34;&#34;&#34;
    Getting TensorFlow callbacks function for convenience purpose.
    Args:
        root (str): Root directory for TensorBoard
        tboard_callback (bool): Whether using TensorBoard or not. Default: True
        tboard_update_freq (str): TensorBoard update frequency. (&#39;epoch&#39;, &#39;batch&#39;). Default: &#39;epoch&#39;
        tboard_histogram_freq (int): TensorBoard histogram update frequency. Default: 1
        tboard_profile_batch (int): TensorBoard profile timing. If 0 is given, profiling is not used.
                                Ex) If 10 is given, profiling is executed at batch of 10. Default: 0
        confuse_callback (bool): Whether using confusion matrix for TensorBoard callback or not.
                          At least one of the following three ((x_test, y_test), test_generator_, test_dataset) must be set.
                          Otherwise, Confusion Matrix callback will be ignored.
                          Default: True.
        label_info (list of str): Names of class. If None, default names are set to (Class01, Class02 ...). Default: None.
        x_test (np.ndarray, None): (n data, data dimension(Ex. 32x32x3 or 600x30 ..., etc). If None is given, dataset must be provided.
        y_test (np.ndarray, None): (n data, ). If None is given, dataset must be provided.
        test_generator_ (tfhelper.dataset.HDF5Generator, None): Default: None. For HDF5Generator test set purpose.
        test_dataset (tf.dataset.Dataset, None): Default: None.
        figure_size (tuple): Figure Size of Confusion Matrix.
        modelsaver_callback (bool): Whether using ModelSaver callback or not. Saving the model file when the lowest validation loss is given per each epochs.
                                        Default: False.
        best_loss (float): Set best score of previous training session if resuming.
        save_root (str): Model save path
        best_epoch (int): Previous Best epoch number if resuming
        save_metric (str): One of &#39;val_loss&#39;, &#39;val_accuracy&#39;
        earlystop_callbac (bool): Early Stop callback
        earlystop_monitor (str): Earlys top_monitor metric &#39;val_loss&#39;, &#39;val_accuracy&#39;
        earlystop_patience (int): Early stop patience
        earlystop_restore_weights (bool): Restore weights on early stop.
        sparsity_callback (bool): Sparsity callback.
        sparsity_threshold (float): Sparsity Threshold of each layer.
                            Ex) 0.05 -&gt; Find the number of weights where -0.05 &lt; values &lt; 0.05 in a layer.
                            Percentage of the number if set to the sparsity of the layer.

    Returns:
        list of tf.keras.callbacks.Callback: Callback List
        str: Tensor Board Log Root Directory

    &#34;&#34;&#34;
    postfix = datetime.datetime.now().strftime(&#34;%Y%m%d-%H%M%S&#34;)
    log_root_ = &#34;{}{}/&#34;.format(root, postfix)

    callbacks_ = []

    if tboard_callback:
        callbacks_.append(tf.keras.callbacks.TensorBoard(log_dir=&#34;{}fit&#34;.format(log_root_),
                                                         histogram_freq=tboard_histogram_freq,
                                                         update_freq=tboard_update_freq,
                                                         profile_batch=tboard_profile_batch)
                         )

    if confuse_callback:
        file_writer = tf.summary.create_file_writer(&#34;{}/cm&#34;.format(log_root_, postfix))

        x_test = test_generator_.data[&#39;test_data&#39;] if test_generator_ is not None else x_test
        y_test = test_generator_.data[&#39;test_label&#39;] if test_generator_ is not None else y_test

        if x_test is not None and y_test is not None:
            callbacks_.append(ConfuseCallback(x_test, y_test, file_writer, class_names=label_info,
                                              figure_size=figure_size)
                              )
        elif test_dataset is not None:
            callbacks_.append(ConfuseCallback(None, None, file_writer, dataset=test_dataset, class_names=label_info,
                                              figure_size=figure_size)
                              )

    if modelsaver_callback:
        if not save_root:
            save_root = log_root_
        callbacks_.append(
            ModelSaverCallback(best_metric=best_loss, save_root=save_root, epoch=best_epoch, save_metric=save_metric)
        )

    if earlystop_callback:
        callbacks_.append(tf.keras.callbacks.EarlyStopping(monitor=earlystop_monitor, patience=earlystop_patience,
                                                           restore_best_weights=earlystop_restore_weights))

    if sparsity_callback:
        file_writer = tf.summary.create_file_writer(&#34;{}/sparsity&#34;.format(log_root_, postfix))

        callbacks_.append(
            SparsityCallback(file_writer, sparsity_threshold=sparsity_threshold)
        )

    return callbacks_, log_root_</code></pre>
</details>
</dd>
<dt id="tfhelper.tensorboard.tensorboard.run_tensorboard"><code class="name flex">
<span>def <span class="ident">run_tensorboard</span></span>(<span>path, host='0.0.0.0', port=6006)</span>
</code></dt>
<dd>
<div class="desc"><p>Run TensorBoard in python script.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>TensorBoard log dir</dd>
<dt>host(str): Host address for TensorBoard.</dt>
<dt>127.0.0.1 -&gt; localhost.</dt>
<dt>0.0.0.0 -&gt; Allow remote connection.</dt>
<dt><strong><code>port</code></strong> :&ensp;<code>int</code></dt>
<dd>Port number for TensorBoard</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_tensorboard(path, host=&#39;0.0.0.0&#39;, port=6006):
    &#34;&#34;&#34;
    Run TensorBoard in python script.
    Args:
        path (str): TensorBoard log dir
        host(str): Host address for TensorBoard.
                    127.0.0.1 -&gt; localhost.
                    0.0.0.0 -&gt; Allow remote connection.
        port (int): Port number for TensorBoard

    Returns:
        None
    &#34;&#34;&#34;
    tb = program.TensorBoard()
    tb.configure(argv=[None, &#39;--logdir&#39;, path, &#39;--host&#39;, host, &#39;--port&#39;, f&#34;{port:}&#34;])
    url = tb.launch()

    print(&#34;Running tensorboard on {}&#34;.format(url))

    return url</code></pre>
</details>
</dd>
<dt id="tfhelper.tensorboard.tensorboard.wait_ctrl_c"><code class="name flex">
<span>def <span class="ident">wait_ctrl_c</span></span>(<span>pre_msg='Press Ctrl+c to quit Tensorboard', post_msg='\nExit.')</span>
</code></dt>
<dd>
<div class="desc"><p>Wait until ctrl+c is pressed. This function is to prevent quitting python process when the training is completed when TensorBoard is running.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>pre_msg</code></strong></dt>
<dd>Message prior to wait ctrl+c</dd>
<dt><strong><code>post_msg</code></strong></dt>
<dd>Message post to ctrl+c pressed</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def wait_ctrl_c(pre_msg=&#34;Press Ctrl+c to quit Tensorboard&#34;, post_msg=&#34;\nExit.&#34;):
    &#34;&#34;&#34;
    Wait until ctrl+c is pressed. This function is to prevent quitting python process when the training is completed when TensorBoard is running.
    Args:
        pre_msg: Message prior to wait ctrl+c
        post_msg: Message post to ctrl+c pressed

    Returns:
        None
    &#34;&#34;&#34;
    print(pre_msg)
    try:
        while True:
            time.sleep(3600)
    except KeyboardInterrupt:
        print(post_msg)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tfhelper.tensorboard.tensorboard.ConfuseCallback"><code class="flex name class">
<span>class <span class="ident">ConfuseCallback</span></span>
<span>(</span><span>x_test, y_test, file_writer, dataset=None, class_names=None, figure_size=(12, 10), batch_size=32)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate Confusion Matrix and write an image to TensorBoard</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x_test</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>(n data, data dimension(Ex. 32x32x3 or 600x30 &hellip;, etc). If None is given, dataset must be provided.</dd>
<dt><strong><code>y_test</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>(n data, ). If None is given, dataset must be provided.</dd>
<dt><strong><code>file_writer</code></strong> :&ensp;<code>tf.summary.SummaryWriter</code></dt>
<dd>TensorBoard File Writer</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<code>tf.keras.dataset.Dataset</code></dt>
<dd>If dataset is given, x_test and y_test is ignored. Default: None.</dd>
<dt><strong><code>class_names</code></strong> :&ensp;<code>list</code> of <code>str</code></dt>
<dd>Names of class. If None, default names are set to (Class01, Class02 &hellip;). Default: None.</dd>
<dt><strong><code>figure_size</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Figure size of confusion matrix. Default: (12, 10).</dd>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Batch size to predict x_test. If dataset is given, batch_size is ignored and batch size set in dataset is used.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ConfuseCallback(tf.keras.callbacks.Callback):
    &#34;&#34;&#34;
    Generate Confusion Matrix and write an image to TensorBoard
    &#34;&#34;&#34;
    def __init__(self, x_test, y_test, file_writer, dataset=None, class_names=None, figure_size=(12, 10), batch_size=32):
        &#34;&#34;&#34;
        Args:
            x_test (np.ndarray): (n data, data dimension(Ex. 32x32x3 or 600x30 ..., etc). If None is given, dataset must be provided.
            y_test (np.ndarray): (n data, ). If None is given, dataset must be provided.
            file_writer (tf.summary.SummaryWriter): TensorBoard File Writer
            dataset (tf.keras.dataset.Dataset): If dataset is given, x_test and y_test is ignored. Default: None.
            class_names (list of str): Names of class. If None, default names are set to (Class01, Class02 ...). Default: None.
            figure_size (tuple): Figure size of confusion matrix. Default: (12, 10).
            batch_size (int): Batch size to predict x_test. If dataset is given, batch_size is ignored and batch size set in dataset is used.
        &#34;&#34;&#34;
        super(ConfuseCallback, self).__init__()
        self.dataset = dataset
        self.x_test = x_test
        self.y_test = y_test

        if self.y_test is None and self.dataset is not None:
            self.y_test = []
            for i, xy in self.dataset.enumerate():
                y = xy[1].numpy()
                self.y_test = np.concatenate([self.y_test, y])
            self.y_test = self.y_test.astype(np.int32)

        self.y_test = self.y_test if len(self.y_test.shape) == 1 else np.argmax(self.y_test, axis=1)

        self.file_writer = file_writer
        self.figure_size = figure_size
        self.label_names = class_names
        self.batch_size = batch_size

        if self.label_names is None and self.y_test is not None:
            self.label_names = [&#34;Class {:02d}&#34;.format(unique_label) for unique_label in np.unique(self.y_test)]

    def get_precision_recall_plot(self, con_mat):
        &#34;&#34;&#34;
        Generate Precision and Recall plot bar plot image
        Args:
            con_mat (np.ndarray): Confusion Matrix array

        Returns:
            tf.TensorArray: Precision and Recall Bar Plot Image
            np.ndarray: Precisions
            np.ndarray: Recalls
        &#34;&#34;&#34;
        precisions = np.array([0] * len(self.label_names)).astype(&#39;float32&#39;)
        recalls = np.array([0] * len(self.label_names)).astype(&#39;float32&#39;)

        for i in range(con_mat.shape[0]):
            tp = con_mat[i, i]
            fn = (con_mat[i, :].sum() - tp)

            fp = (con_mat[:, i].sum() - tp)
            tn = (con_mat.diagonal().sum() - tp)

            # tpr = tp / np.sum(self.test_labels[()] == i)
            # fnr = fn / np.sum(self.test_labels[()] == i)
            # fpr = fp / np.sum(self.test_labels[()] != i)
            # tnr = tn / np.sum(self.test_labels[()] != i)

            precisions[i] = max(0, tp / (tp + fp))
            recalls[i] = max(0, tp / (tp + fn))

        df = pd.DataFrame((self.label_names, precisions, recalls)).T
        df.columns = [&#34;Class&#34;, &#34;Precision&#34;, &#34;Recall&#34;]
        df = pd.melt(df, id_vars=&#34;Class&#34;, var_name=&#34;Type&#34;, value_name=&#34;Value&#34;)

        figure = plt.figure(figsize=self.figure_size)
        sns.barplot(y=&#39;Class&#39;, x=&#39;Value&#39;, hue=&#39;Type&#39;, data=df)
        plt.tight_layout()

        buf = io.BytesIO()
        plt.savefig(buf, format=&#39;png&#39;)
        plt.close(figure)

        image = tf.image.decode_png(buf.getvalue(), channels=4)
        image = tf.expand_dims(image, 0)

        return image, precisions, recalls

    def on_epoch_end(self, epoch, logs=None):
        if self.dataset is None and (self.x_test is None or self.y_test is None):
            return

        try:
            if self.dataset is None:
                test_pred = []
                for b in range(0, self.x_test.shape[0], self.batch_size):
                    x_feed = self.x_test[b:b+self.batch_size]
                    pred = self.model.predict(x_feed)
                    pred = np.argmax(pred, axis=1)
                    test_pred = np.concatenate([test_pred, pred])
            else:
                test_pred = self.model.predict(self.dataset)
                test_pred = np.argmax(test_pred, axis=1)

            accuracy = np.sum(test_pred == self.y_test) / self.y_test.shape[0]

            con_mat = tf.math.confusion_matrix(labels=self.y_test, predictions=test_pred).numpy()
            con_mat_norm = np.around(con_mat.astype(&#39;float&#39;) / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)

            con_mat_df = pd.DataFrame(con_mat_norm,
                                      index=self.label_names,
                                      columns=self.label_names)

            precision_recall_image, precisions, recalls = self.get_precision_recall_plot(con_mat)

            figure = plt.figure(figsize=self.figure_size)
            sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)
            plt.ylabel(&#39;True label&#39;)
            plt.xlabel(&#39;Predicted label&#39;)
            plt.title(&#34;Accuracy : {:.2f}%, Precision : {:.2f}%, Recall : {:.2f}%&#34;.format(accuracy*100, precisions.mean()*100, recalls.mean()*100))

            plt.tight_layout()

            buf = io.BytesIO()
            plt.savefig(buf, format=&#39;png&#39;)

            plt.close(figure)
            buf.seek(0)
            image = tf.image.decode_png(buf.getvalue(), channels=4)

            image = tf.expand_dims(image, 0)

            # Log the confusion matrix as an image summary.
            with self.file_writer.as_default():
                tf.summary.image(&#34;Confusion Matrix&#34;, image, step=epoch)
                tf.summary.image(&#34;Precision and Recall&#34;, precision_recall_image, step=epoch)
        except Exception as e:
            print(e)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.callbacks.Callback</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="tfhelper.tensorboard.tensorboard.ConfuseCallback.get_precision_recall_plot"><code class="name flex">
<span>def <span class="ident">get_precision_recall_plot</span></span>(<span>self, con_mat)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate Precision and Recall plot bar plot image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>con_mat</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Confusion Matrix array</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tf.TensorArray</code></dt>
<dd>Precision and Recall Bar Plot Image</dd>
<dt><code>np.ndarray</code></dt>
<dd>Precisions</dd>
<dt><code>np.ndarray</code></dt>
<dd>Recalls</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_precision_recall_plot(self, con_mat):
    &#34;&#34;&#34;
    Generate Precision and Recall plot bar plot image
    Args:
        con_mat (np.ndarray): Confusion Matrix array

    Returns:
        tf.TensorArray: Precision and Recall Bar Plot Image
        np.ndarray: Precisions
        np.ndarray: Recalls
    &#34;&#34;&#34;
    precisions = np.array([0] * len(self.label_names)).astype(&#39;float32&#39;)
    recalls = np.array([0] * len(self.label_names)).astype(&#39;float32&#39;)

    for i in range(con_mat.shape[0]):
        tp = con_mat[i, i]
        fn = (con_mat[i, :].sum() - tp)

        fp = (con_mat[:, i].sum() - tp)
        tn = (con_mat.diagonal().sum() - tp)

        # tpr = tp / np.sum(self.test_labels[()] == i)
        # fnr = fn / np.sum(self.test_labels[()] == i)
        # fpr = fp / np.sum(self.test_labels[()] != i)
        # tnr = tn / np.sum(self.test_labels[()] != i)

        precisions[i] = max(0, tp / (tp + fp))
        recalls[i] = max(0, tp / (tp + fn))

    df = pd.DataFrame((self.label_names, precisions, recalls)).T
    df.columns = [&#34;Class&#34;, &#34;Precision&#34;, &#34;Recall&#34;]
    df = pd.melt(df, id_vars=&#34;Class&#34;, var_name=&#34;Type&#34;, value_name=&#34;Value&#34;)

    figure = plt.figure(figsize=self.figure_size)
    sns.barplot(y=&#39;Class&#39;, x=&#39;Value&#39;, hue=&#39;Type&#39;, data=df)
    plt.tight_layout()

    buf = io.BytesIO()
    plt.savefig(buf, format=&#39;png&#39;)
    plt.close(figure)

    image = tf.image.decode_png(buf.getvalue(), channels=4)
    image = tf.expand_dims(image, 0)

    return image, precisions, recalls</code></pre>
</details>
</dd>
<dt id="tfhelper.tensorboard.tensorboard.ConfuseCallback.on_epoch_end"><code class="name flex">
<span>def <span class="ident">on_epoch_end</span></span>(<span>self, epoch, logs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Called at the end of an epoch.</p>
<p>Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.</p>
<h2 id="arguments">Arguments</h2>
<p>epoch: integer, index of epoch.
logs: dict, metric results for this training epoch, and for the
validation epoch if validation is performed. Validation result keys
are prefixed with <code>val_</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_end(self, epoch, logs=None):
    if self.dataset is None and (self.x_test is None or self.y_test is None):
        return

    try:
        if self.dataset is None:
            test_pred = []
            for b in range(0, self.x_test.shape[0], self.batch_size):
                x_feed = self.x_test[b:b+self.batch_size]
                pred = self.model.predict(x_feed)
                pred = np.argmax(pred, axis=1)
                test_pred = np.concatenate([test_pred, pred])
        else:
            test_pred = self.model.predict(self.dataset)
            test_pred = np.argmax(test_pred, axis=1)

        accuracy = np.sum(test_pred == self.y_test) / self.y_test.shape[0]

        con_mat = tf.math.confusion_matrix(labels=self.y_test, predictions=test_pred).numpy()
        con_mat_norm = np.around(con_mat.astype(&#39;float&#39;) / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)

        con_mat_df = pd.DataFrame(con_mat_norm,
                                  index=self.label_names,
                                  columns=self.label_names)

        precision_recall_image, precisions, recalls = self.get_precision_recall_plot(con_mat)

        figure = plt.figure(figsize=self.figure_size)
        sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)
        plt.ylabel(&#39;True label&#39;)
        plt.xlabel(&#39;Predicted label&#39;)
        plt.title(&#34;Accuracy : {:.2f}%, Precision : {:.2f}%, Recall : {:.2f}%&#34;.format(accuracy*100, precisions.mean()*100, recalls.mean()*100))

        plt.tight_layout()

        buf = io.BytesIO()
        plt.savefig(buf, format=&#39;png&#39;)

        plt.close(figure)
        buf.seek(0)
        image = tf.image.decode_png(buf.getvalue(), channels=4)

        image = tf.expand_dims(image, 0)

        # Log the confusion matrix as an image summary.
        with self.file_writer.as_default():
            tf.summary.image(&#34;Confusion Matrix&#34;, image, step=epoch)
            tf.summary.image(&#34;Precision and Recall&#34;, precision_recall_image, step=epoch)
    except Exception as e:
        print(e)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="tfhelper.tensorboard.tensorboard.ModelSaverCallback"><code class="flex name class">
<span>class <span class="ident">ModelSaverCallback</span></span>
<span>(</span><span>best_metric=inf, save_root='./', save_metric='val_loss', enable=True, epoch=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves Model at each end of the epoch when the best accuracy/loss is presented.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>best_metric</code></strong> :&ensp;<code>float</code></dt>
<dd>Set best score of previous training session if resuming.</dd>
<dt><strong><code>save_root</code></strong> :&ensp;<code>str</code></dt>
<dd>Model save path</dd>
<dt><strong><code>save_metric</code></strong> :&ensp;<code>str</code></dt>
<dd>One of 'val_loss', 'val_accuracy'</dd>
<dt><strong><code>enable</code></strong> :&ensp;<code>bool</code></dt>
<dd>Set previous epoch number if resuming</dd>
<dt><strong><code>epoch</code></strong> :&ensp;<code>int</code></dt>
<dd>Epoch number</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ModelSaverCallback(tf.keras.callbacks.Callback):
    &#34;&#34;&#34;
    Saves Model at each end of the epoch when the best accuracy/loss is presented.
    &#34;&#34;&#34;
    def __init__(self, best_metric=float(&#39;inf&#39;), save_root=&#34;./&#34;, save_metric=&#39;val_loss&#39;, enable=True, epoch=0):
        &#34;&#34;&#34;

        Args:
            best_metric (float): Set best score of previous training session if resuming.
            save_root (str): Model save path
            save_metric (str): One of &#39;val_loss&#39;, &#39;val_accuracy&#39;
            enable (bool): Set previous epoch number if resuming
            epoch (int): Epoch number
        &#34;&#34;&#34;
        super(ModelSaverCallback, self).__init__()
        self.best_metric = best_metric
        if self.best_metric == float(&#39;inf&#39;) and save_metric.find(&#34;accuracy&#34;) &gt; 0:
            self.best_metric = -self.best_metric

        self.epoch = epoch
        self.save_root = save_root
        self.enable = enable
        self.save_metric = save_metric

    def on_epoch_end(self, epoch, logs=None):
        try:
            epoch += self.epoch
            a = logs[self.save_metric]
            b = self.best_metric

            if self.save_metric.find(&#34;accuracy&#34;) &gt; 0:
                a, b = b, a

            if a &lt; b:
                p_file_list = glob.glob(&#34;{}/*.h5&#34;.format(self.save_root))
                p_file_list = sorted(p_file_list, key=lambda x: x[-10:])
                if self.save_metric.find(&#34;accuracy&#34;) &lt; 0:
                    p_file_list = p_file_list[::-1]

                for i, file_path in enumerate(p_file_list):
                    if i+1 == len(p_file_list):
                        break
                    try:
                        os.remove(file_path)
                    except:
                        print(&#34;Error while deleting file : {}&#34;.format(file_path))

                file_name = &#39;{}/my_model_weight_{:04d}_{}_{:03.2f}.h5&#39;.format(self.save_root, epoch, self.save_metric, logs[self.save_metric])
                print(&#34;\nBest score! saving the model to {} ...&#34;.format(file_name))
                self.best_metric = logs[self.save_metric]

                if self.enable:
                    self.model.save(file_name)
        except Exception as e:
            print(e)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.callbacks.Callback</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="tfhelper.tensorboard.tensorboard.ModelSaverCallback.on_epoch_end"><code class="name flex">
<span>def <span class="ident">on_epoch_end</span></span>(<span>self, epoch, logs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Called at the end of an epoch.</p>
<p>Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.</p>
<h2 id="arguments">Arguments</h2>
<p>epoch: integer, index of epoch.
logs: dict, metric results for this training epoch, and for the
validation epoch if validation is performed. Validation result keys
are prefixed with <code>val_</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_end(self, epoch, logs=None):
    try:
        epoch += self.epoch
        a = logs[self.save_metric]
        b = self.best_metric

        if self.save_metric.find(&#34;accuracy&#34;) &gt; 0:
            a, b = b, a

        if a &lt; b:
            p_file_list = glob.glob(&#34;{}/*.h5&#34;.format(self.save_root))
            p_file_list = sorted(p_file_list, key=lambda x: x[-10:])
            if self.save_metric.find(&#34;accuracy&#34;) &lt; 0:
                p_file_list = p_file_list[::-1]

            for i, file_path in enumerate(p_file_list):
                if i+1 == len(p_file_list):
                    break
                try:
                    os.remove(file_path)
                except:
                    print(&#34;Error while deleting file : {}&#34;.format(file_path))

            file_name = &#39;{}/my_model_weight_{:04d}_{}_{:03.2f}.h5&#39;.format(self.save_root, epoch, self.save_metric, logs[self.save_metric])
            print(&#34;\nBest score! saving the model to {} ...&#34;.format(file_name))
            self.best_metric = logs[self.save_metric]

            if self.enable:
                self.model.save(file_name)
    except Exception as e:
        print(e)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="tfhelper.tensorboard.tensorboard.SparsityCallback"><code class="flex name class">
<span>class <span class="ident">SparsityCallback</span></span>
<span>(</span><span>file_writer, sparsity_threshold=0.05, figure_size=(12, 20))</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the sparsity on each layer of the given model and saves bar plot image to the TensorBoard.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_writer</code></strong> :&ensp;<code>tf.summary.SummaryWriter</code></dt>
<dd>TensorBoard File Writer</dd>
<dt><strong><code>sparsity_threshold</code></strong> :&ensp;<code>float</code></dt>
<dd>Sparsity Threshold of each layer.
Ex) 0.05 -&gt; Find the number of weights where -0.05 &lt; values &lt; 0.05 in a layer.
Percentage of the number if set to the sparsity of the layer.</dd>
<dt><strong><code>figure_size</code></strong> :&ensp;<code>tuple</code></dt>
<dd>Figure size to generate plot image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SparsityCallback(tf.keras.callbacks.Callback):
    &#34;&#34;&#34;
    Computes the sparsity on each layer of the given model and saves bar plot image to the TensorBoard.
    &#34;&#34;&#34;
    def __init__(self, file_writer, sparsity_threshold=0.05, figure_size=(12, 20)):
        &#34;&#34;&#34;

        Args:
            file_writer (tf.summary.SummaryWriter): TensorBoard File Writer
            sparsity_threshold (float): Sparsity Threshold of each layer.
                                        Ex) 0.05 -&gt; Find the number of weights where -0.05 &lt; values &lt; 0.05 in a layer.
                                        Percentage of the number if set to the sparsity of the layer.
            figure_size (tuple): Figure size to generate plot image
        &#34;&#34;&#34;
        super(SparsityCallback, self).__init__()

        self.file_writer = file_writer
        self.sparsity_threshold = sparsity_threshold
        self.figure_size = list(figure_size)

    def get_sparsity_plot(self, sparse_levels, sparse_layer_names):
        &#34;&#34;&#34;
        Generate sparsity plot image

        Args:
            sparse_levels (np.ndarray): Sparse levels for the layer
            sparse_layer_names (list of str, np.ndarray): Names of layer along with sparse_levels list

        Returns:

        &#34;&#34;&#34;
        width = 0.8

        n_data = sparse_levels.shape[0]
        self.figure_size[1] = 0.25 * n_data

        fig, ax = plt.subplots(figsize=self.figure_size)
        ax.barh(sparse_layer_names, sparse_levels, width)

        for i, v in enumerate(sparse_levels):
            ax.text(v + 0.005, i - .15, f&#34;{v * 100:.2f}%&#34;, color=&#39;k&#39;, fontweight=&#39;bold&#39;)

        ax.set_title(f&#34;Sparsity Threshold: {self.sparsity_threshold}, Mean Sparsity: {sparse_levels.mean()*100:.2f}%&#34;)
        ax.set_xlim(0.0, 1.0)

        buf = io.BytesIO()
        fig.savefig(buf, format=&#39;png&#39;)
        plt.close(fig)

        image = tf.image.decode_png(buf.getvalue(), channels=4)
        image = tf.expand_dims(image, 0)

        return image

    def on_epoch_end(self, epoch, logs=None):
        sparsities = self.compute_sparsity()
        layer_names = [layer.name for layer in self.model.layers]

        sparse_levels = []
        sparse_layer_names = []

        for i, (sparsity, layer_name) in enumerate(zip(sparsities, layer_names)):
            if np.isnan(sparsity):
                continue
            sparse_levels = np.concatenate([sparse_levels, [sparsity]])
            sparse_layer_names = np.concatenate([sparse_layer_names, [f&#34;{i:03d}: {layer_name}&#34;]])

        try:
            sparsity_image = self.get_sparsity_plot(sparse_levels, sparse_layer_names)

            with self.file_writer.as_default():
                tf.summary.image(&#34;Sparsity Levels of Each Layer&#34;, sparsity_image, step=epoch)
        except Exception as e:
            print(e)

    def compute_sparsity(self):
        sparsities = np.zeros(len(self.model.layers))

        for i in range(sparsities.shape[0]):
            if len(self.model.layers[i].weights) &lt; 1:
                sparsities[i] = np.nan
                continue

            sparse_index = np.argwhere(
                np.logical_and(self.model.layers[i].weights[0].numpy().flatten() &lt; self.sparsity_threshold,
                               self.model.layers[i].weights[0].numpy().flatten() &gt; -self.sparsity_threshold))

            sparsities[i] = sparse_index.shape[0] / np.prod(self.model.layers[i].weights[0].shape)

        return sparsities</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>tensorflow.python.keras.callbacks.Callback</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="tfhelper.tensorboard.tensorboard.SparsityCallback.compute_sparsity"><code class="name flex">
<span>def <span class="ident">compute_sparsity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_sparsity(self):
    sparsities = np.zeros(len(self.model.layers))

    for i in range(sparsities.shape[0]):
        if len(self.model.layers[i].weights) &lt; 1:
            sparsities[i] = np.nan
            continue

        sparse_index = np.argwhere(
            np.logical_and(self.model.layers[i].weights[0].numpy().flatten() &lt; self.sparsity_threshold,
                           self.model.layers[i].weights[0].numpy().flatten() &gt; -self.sparsity_threshold))

        sparsities[i] = sparse_index.shape[0] / np.prod(self.model.layers[i].weights[0].shape)

    return sparsities</code></pre>
</details>
</dd>
<dt id="tfhelper.tensorboard.tensorboard.SparsityCallback.get_sparsity_plot"><code class="name flex">
<span>def <span class="ident">get_sparsity_plot</span></span>(<span>self, sparse_levels, sparse_layer_names)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate sparsity plot image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sparse_levels</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Sparse levels for the layer</dd>
<dt><strong><code>sparse_layer_names</code></strong> :&ensp;<code>list</code> of <code>str, np.ndarray</code></dt>
<dd>Names of layer along with sparse_levels list</dd>
</dl>
<p>Returns:</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_sparsity_plot(self, sparse_levels, sparse_layer_names):
    &#34;&#34;&#34;
    Generate sparsity plot image

    Args:
        sparse_levels (np.ndarray): Sparse levels for the layer
        sparse_layer_names (list of str, np.ndarray): Names of layer along with sparse_levels list

    Returns:

    &#34;&#34;&#34;
    width = 0.8

    n_data = sparse_levels.shape[0]
    self.figure_size[1] = 0.25 * n_data

    fig, ax = plt.subplots(figsize=self.figure_size)
    ax.barh(sparse_layer_names, sparse_levels, width)

    for i, v in enumerate(sparse_levels):
        ax.text(v + 0.005, i - .15, f&#34;{v * 100:.2f}%&#34;, color=&#39;k&#39;, fontweight=&#39;bold&#39;)

    ax.set_title(f&#34;Sparsity Threshold: {self.sparsity_threshold}, Mean Sparsity: {sparse_levels.mean()*100:.2f}%&#34;)
    ax.set_xlim(0.0, 1.0)

    buf = io.BytesIO()
    fig.savefig(buf, format=&#39;png&#39;)
    plt.close(fig)

    image = tf.image.decode_png(buf.getvalue(), channels=4)
    image = tf.expand_dims(image, 0)

    return image</code></pre>
</details>
</dd>
<dt id="tfhelper.tensorboard.tensorboard.SparsityCallback.on_epoch_end"><code class="name flex">
<span>def <span class="ident">on_epoch_end</span></span>(<span>self, epoch, logs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Called at the end of an epoch.</p>
<p>Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.</p>
<h2 id="arguments">Arguments</h2>
<p>epoch: integer, index of epoch.
logs: dict, metric results for this training epoch, and for the
validation epoch if validation is performed. Validation result keys
are prefixed with <code>val_</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_end(self, epoch, logs=None):
    sparsities = self.compute_sparsity()
    layer_names = [layer.name for layer in self.model.layers]

    sparse_levels = []
    sparse_layer_names = []

    for i, (sparsity, layer_name) in enumerate(zip(sparsities, layer_names)):
        if np.isnan(sparsity):
            continue
        sparse_levels = np.concatenate([sparse_levels, [sparsity]])
        sparse_layer_names = np.concatenate([sparse_layer_names, [f&#34;{i:03d}: {layer_name}&#34;]])

    try:
        sparsity_image = self.get_sparsity_plot(sparse_levels, sparse_layer_names)

        with self.file_writer.as_default():
            tf.summary.image(&#34;Sparsity Levels of Each Layer&#34;, sparsity_image, step=epoch)
    except Exception as e:
        print(e)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tfhelper.tensorboard" href="index.html">tfhelper.tensorboard</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="tfhelper.tensorboard.tensorboard.get_tf_callbacks" href="#tfhelper.tensorboard.tensorboard.get_tf_callbacks">get_tf_callbacks</a></code></li>
<li><code><a title="tfhelper.tensorboard.tensorboard.run_tensorboard" href="#tfhelper.tensorboard.tensorboard.run_tensorboard">run_tensorboard</a></code></li>
<li><code><a title="tfhelper.tensorboard.tensorboard.wait_ctrl_c" href="#tfhelper.tensorboard.tensorboard.wait_ctrl_c">wait_ctrl_c</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tfhelper.tensorboard.tensorboard.ConfuseCallback" href="#tfhelper.tensorboard.tensorboard.ConfuseCallback">ConfuseCallback</a></code></h4>
<ul class="">
<li><code><a title="tfhelper.tensorboard.tensorboard.ConfuseCallback.get_precision_recall_plot" href="#tfhelper.tensorboard.tensorboard.ConfuseCallback.get_precision_recall_plot">get_precision_recall_plot</a></code></li>
<li><code><a title="tfhelper.tensorboard.tensorboard.ConfuseCallback.on_epoch_end" href="#tfhelper.tensorboard.tensorboard.ConfuseCallback.on_epoch_end">on_epoch_end</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tfhelper.tensorboard.tensorboard.ModelSaverCallback" href="#tfhelper.tensorboard.tensorboard.ModelSaverCallback">ModelSaverCallback</a></code></h4>
<ul class="">
<li><code><a title="tfhelper.tensorboard.tensorboard.ModelSaverCallback.on_epoch_end" href="#tfhelper.tensorboard.tensorboard.ModelSaverCallback.on_epoch_end">on_epoch_end</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tfhelper.tensorboard.tensorboard.SparsityCallback" href="#tfhelper.tensorboard.tensorboard.SparsityCallback">SparsityCallback</a></code></h4>
<ul class="">
<li><code><a title="tfhelper.tensorboard.tensorboard.SparsityCallback.compute_sparsity" href="#tfhelper.tensorboard.tensorboard.SparsityCallback.compute_sparsity">compute_sparsity</a></code></li>
<li><code><a title="tfhelper.tensorboard.tensorboard.SparsityCallback.get_sparsity_plot" href="#tfhelper.tensorboard.tensorboard.SparsityCallback.get_sparsity_plot">get_sparsity_plot</a></code></li>
<li><code><a title="tfhelper.tensorboard.tensorboard.SparsityCallback.on_epoch_end" href="#tfhelper.tensorboard.tensorboard.SparsityCallback.on_epoch_end">on_epoch_end</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.4</a>.</p>
</footer>
</body>
</html>